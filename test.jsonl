{"unique_id": "hateful_memes_test_unseen_15740", "image_source": "hateful_memes", "task_name": "visual_text_extraction", "image_path": "./raw_datasets/hateful_memes/img/15740.png", "target_txt": "when someone tells you how to bbq", "meta_data": {"label": "Yes"}, "prompt": "What is the text written on the image?", "target": "when someone tells you how to bbq"}
{"unique_id": "visual7w_pointing_5_294367", "image_source": "Visual7W", "task_name": "grounded_VQA", "image_path": "raw_datasets/visual7w/images/v7w_5.jpg", "region": ["144 358 318 598"], "question": "Which item in the photo is the chair at the desk?", "options": ["3 8 43 537", "347 453 410 580", "2 490 351 598", "144 358 318 598"], "meta_data": {"object": "chair", "question_type": "which"}, "target_txt": "144 358 318 598", "prompt": "Which item in the photo is the chair at the desk?\n\n[Options]: 3 8 43 537||||347 453 410 580||||2 490 351 598||||144 358 318 598", "target": "144 358 318 598"}
{"unique_id": "medic_test_0_disaster_types", "image_source": "medic", "task_name": "medic_disaster_types", "image_path": "/projects/nlp_lab/yings/mata_data/medic/data/ASONAM17_Damage_Image_Dataset/ecuador_eq/ecuador_eq_mild_im_121.jpg", "target_txt": "earthquake", "options": ["little or none damage", "not informative", "hurricane", "informative", "fire", "severe damage", "not disaster", "mild damage", "landslide", "other disaster", "flood", "earthquake"], "meta_data": {"task_cat": "disaster_types", "options": ["earthquake", "fire", "flood", "hurricane", "landslide", "not disaster", "other disaster"]}, "prompt": "What kind of disaster happens in the image? If no disaster happens in the image, select not disaster.\n\n[Options]: little or none damage||||not informative||||hurricane||||informative||||fire||||severe damage||||not disaster||||mild damage||||landslide||||other disaster||||flood||||earthquake", "target": "earthquake"}
{"unique_id": "text_vqa_val_003a8ae2ef43b901", "image_source": "text_vqa", "task_name": "text_vqa", "image_path": "raw_datasets/TextVQA/train_val/train_images/003a8ae2ef43b901.jpg", "target_txt": "dakota", "question": "what is the brand of this camera?", "meta_data": {"answers": ["nous les gosses", "dakota", "clos culombu", "dakota digital", "dakota", "dakota", "dakota digital", "dakota digital", "dakota", "dakota"], "image_classes": ["Cassette deck", "Printer", "Medical equipment", "Computer mouse", "Scale", "Telephone", "Camera", "Ipod", "Remote control"]}, "prompt": "Look at the image and what is the brand of this camera?", "target": "dakota"}
{"unique_id": "vcr_val-0", "image_source": "vcr", "task_name": "commonsense_VQA", "image_path": "raw_datasets/VCR/vcr1images/lsmdc_1054_Harry_Potter_and_the_prisoner_of_azkaban/1054_Harry_Potter_and_the_prisoner_of_azkaban_00.01.46.736-00.01.50.168@0.jpg", "target_txt": "person 1 is upset and disgusted .", "question": "How is person 1 feeling ?", "options": ["person 1 is feeling uncomfortable with person 3 .", "person 1 is feeling very scared .", "person 1 is upset and disgusted .", "person 1 is feeling amused ."], "meta_data": {"object_regions": {"person 1": ["955.7418212890625 52.329559326171875 1551.5677490234375 789.0325927734375"], "person 3": ["902.0066528320312 111.65625 1035.2879638671875 701.32861328125"]}}, "prompt": "How is person 1 feeling ? person 1 is in 955.7418212890625 52.329559326171875 1551.5677490234375 789.0325927734375. person 3 is in 902.0066528320312 111.65625 1035.2879638671875 701.32861328125.\n\n[Options]: person 1 is feeling uncomfortable with person 3 .||||person 1 is feeling very scared .||||person 1 is upset and disgusted .||||person 1 is feeling amused .", "target": "person 1 is upset and disgusted ."}
{"unique_id": "nlvr_0_1406-1", "task_name": "natural_language_visual_reasoning", "image_path": "raw_datasets/nlvr/nlvr/nlvr/test/images/0/test-1406-1-4.png", "text": "There is a black circle closely touching right wall of a box.", "target_txt": "yes", "options": ["no", "yes"], "prompt": "\"There is a black circle closely touching right wall of a box.\"\n\nIs the above text true based on the picture?\n\n[Options]: no||||yes", "target": "yes"}
{"unique_id": "visual_spatial_reasoning_test_0", "task_name": "visual_spatial_reasoning", "image_path": "raw_datasets/visual_spatial_reasoning/visual-spatial-reasoning/data/trainval2017/000000334671.jpg", "text": "The backpack is between the bed.", "target_txt": "no", "options": ["no", "yes"], "prompt": "Can the image support \"The backpack is between the bed.\"?\n\n[Options]: no||||yes", "target": "no"}
{"unique_id": "Flickr30K_ID_1016887272_1016887272.jpg#4r1c", "image_source": "Flickr30K_ID", "task_name": "visual_nli", "image_path": "./raw_datasets/SNLI-VE/SNLI-VE/data/Flickr30K/images/1016887272.jpg", "target_txt": "no", "text": "The person is on the swings.", "options": ["no", "yes", "not sure"], "meta_data": {"caption": "A collage of one person climbing a cliff."}, "prompt": "Can you conclude \"The person is on the swings.\" from the content of image?\n\n[Options]: no||||yes||||not sure", "target": "no"}
{"unique_id": "visdial_val_185565", "image_source": "visdial", "task_name": "visual_dialog", "image_path": "raw_datasets/visdial/VisualDialog_val2018/VisualDialog_val2018_000000185565.jpg", "question": "is the photo in color", "target_txt": "yes", "meta_data": {"caption": "a bedroom is filled with lots of posters and a busy computer desk", "dialog_hist": []}, "prompt": "Given the image, answer the question.\n\nQuestion: is the photo in color?", "target": "yes"}
{"unique_id": "medic_test_0_informative", "image_source": "medic", "task_name": "medic_informative", "image_path": "/projects/nlp_lab/yings/mata_data/medic/data/ASONAM17_Damage_Image_Dataset/ecuador_eq/ecuador_eq_mild_im_121.jpg", "target_txt": "informative", "options": ["informative", "little or none damage", "severe damage", "not informative", "hurricane", "landslide", "earthquake", "mild damage", "not disaster", "flood", "fire", "other disaster"], "meta_data": {"task_cat": "informative", "options": ["informative", "not informative"]}, "prompt": "If this picture is about a disaster, select informative. Otherwise, select not informative from options.\n\n[Options]: informative||||little or none damage||||severe damage||||not informative||||hurricane||||landslide||||earthquake||||mild damage||||not disaster||||flood||||fire||||other disaster", "target": "informative"}
{"unique_id": "medic_test_0_damage_severity", "image_source": "medic", "task_name": "medic_damage_severity", "image_path": "/projects/nlp_lab/yings/mata_data/medic/data/ASONAM17_Damage_Image_Dataset/ecuador_eq/ecuador_eq_mild_im_121.jpg", "target_txt": "mild damage", "options": ["informative", "landslide", "severe damage", "fire", "hurricane", "not informative", "mild damage", "earthquake", "other disaster", "little or none damage", "not disaster", "flood"], "meta_data": {"task_cat": "damage_severity", "options": ["severe damage", "mild damage", "little or none damage"]}, "prompt": "What is the damage level in the image?", "target": "mild damage"}
